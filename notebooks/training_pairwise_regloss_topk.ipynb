{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreya34/matryoshka/beir/beir/datasets/data_loader.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from beir.beir.datasets.data_loader import GenericDataLoader\n",
    "\n",
    "from matryoshka import Matryoshka, PairwiseSimilarityLoss, PairwiseSimilarityLossParallel, RegularizingLoss, TopKSimilarityLoss\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Using cached wandb-0.19.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb) (3.11.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (4.24.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.10.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Using cached sentry_sdk-2.19.2-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Using cached setproctitle-1.3.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.11/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=2.6->wandb) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (3.0.5)\n",
      "Using cached wandb-0.19.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.0 MB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached sentry_sdk-2.19.2-py2.py3-none-any.whl (322 kB)\n",
      "Using cached setproctitle-1.3.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Installing collected packages: setproctitle, sentry-sdk, docker-pycreds, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 sentry-sdk-2.19.2 setproctitle-1.3.4 wandb-0.19.1\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270604a2cfae42dfacd1c340aeaac4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"data/nfcorpus\"\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"train\")\n",
    "\n",
    "length = None\n",
    "corpus = {k: v for k, v in list(corpus.items())[:length]}\n",
    "queries = {k: v for k, v in list(queries.items())[:length]}\n",
    "qrels = {k: v for k, v in list(qrels.items())[:length]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "base_model = Matryoshka(matryoshka_dim=768, adaptor=False)\n",
    "model = Matryoshka(matryoshka_dim=768, adaptor=True)\n",
    "tokenizer = model.tokenizer\n",
    "\n",
    "sentences = [\"sentence\"]\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    base_model = base_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = [c[\"text\"] for c in corpus.values()]\n",
    "qs = list(queries.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, tokenizer, chunk_size=512, overlap=50):\n",
    "    \"\"\"\n",
    "    Splits text into overlapping chunks.\n",
    "    Args:\n",
    "        text: input string\n",
    "        tokenizer: tokenizer instance\n",
    "        chunk_size: max token size for each chunk\n",
    "        overlap: overlap between consecutive chunks\n",
    "    Returns:\n",
    "        List of tokenized chunks (strings)\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(text)  # Tokenize input text\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size - overlap):\n",
    "        chunk = tokens[i:i + chunk_size]\n",
    "        chunks.append(tokenizer.convert_tokens_to_string(chunk))\n",
    "        if len(chunk) < chunk_size:\n",
    "            break\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "Batch: 576 loss: 1.4785133957862855\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "Batch: 1216 loss: 1.4668502449989318\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "Batch: 1856 loss: 1.4672417044639587\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "Batch: 2496 loss: 1.4672711610794067\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "Batch: 3136 loss: 1.4685245037078858\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "Batch: 3776 loss: 1.47001770734787\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "Batch: 4416 loss: 1.466200590133667\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "4992\n",
      "5056\n",
      "Batch: 5056 loss: 1.4673577785491942\n",
      "5120\n",
      "5184\n",
      "5248\n",
      "5312\n",
      "5376\n",
      "5440\n",
      "5504\n",
      "5568\n",
      "5632\n",
      "5696\n",
      "Batch: 5696 loss: 1.4688364624977113\n",
      "5760\n",
      "5824\n",
      "5888\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m target_outputs \u001b[38;5;241m=\u001b[39m process_long_texts(q, base_model, tokenizer, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Compute the losses\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m loss, loss_partial \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m eval_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Collect partial losses\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/matryoshka/matryoshka.py:75\u001b[0m, in \u001b[0;36mPairwiseSimilarityLossParallel.forward\u001b[0;34m(self, embeddings, adapted_embeddings, m_list, reduce)\u001b[0m\n\u001b[1;32m     73\u001b[0m cloned_adapted \u001b[38;5;241m=\u001b[39m adapted_embeddings[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mlen\u001b[39m(adapted_embeddings), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m m_list:\n\u001b[0;32m---> 75\u001b[0m     reduced_similarity \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcosine_similarity(cloned_adapted[i:, :m], \u001b[43madapted_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     76\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mabs((reduced_similarity \u001b[38;5;241m-\u001b[39m target_similarity)))\n\u001b[1;32m     77\u001b[0m     partial_loss[m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mabs((reduced_similarity \u001b[38;5;241m-\u001b[39m target_similarity)))\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "run_name = \"pairwise_reg_topk_skip_layernorm\"\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "running_loss_step = 10\n",
    "learning_rate = 1e-5\n",
    "\n",
    "device = \"cuda\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = PairwiseSimilarityLossParallel()\n",
    "loss_fn_reg = RegularizingLoss()\n",
    "loss_fn_topk = TopKSimilarityLoss(k=10)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "data = qs + cs\n",
    "random.shuffle(data)\n",
    "train_data = data[:int(len(data) * 0.95)]\n",
    "test_data = data[int(len(data) * 0.95):]\n",
    "\n",
    "\n",
    "def process_long_texts(text_list, model, tokenizer, train=True):\n",
    "    final_embeddings = []\n",
    "    for text in text_list:\n",
    "        chunks = chunk_text(text, tokenizer, chunk_size=512)\n",
    "        chunk_embeddings = []\n",
    "\n",
    "        if train = True:\n",
    "            for chunk in chunks:\n",
    "                inputs = tokenizer(chunk, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "                embedding = model(pooling=True, **inputs)  # Always calculate gradients during training\n",
    "                chunk_embeddings.append(embedding.squeeze(0))\n",
    "            \n",
    "            # Replace hard mean pooling with a learnable weighted aggregation\n",
    "            chunk_embeddings = torch.stack(chunk_embeddings)\n",
    "            final_embedding = torch.mean(chunk_embeddings, dim=0) if not train else chunk_embeddings.mean(dim=0, keepdim=True)\n",
    "            final_embeddings.append(final_embedding)\n",
    "\n",
    "        else:\n",
    "            \n",
    "\n",
    "    return torch.cat(final_embeddings)  # Proper gradient flow maintained\n",
    "\n",
    "\n",
    "\n",
    "ls = []\n",
    "for i in range(epochs):\n",
    "    epoch_loss = []\n",
    "    running_loss = []\n",
    "    partial_running_loss = {64: [], 128: [], 256: [], 384: [], 768:[]}\n",
    "\n",
    "    model.train()\n",
    "    random.shuffle(train_data)\n",
    "    for j in range(0, len(train_data), batch_size):\n",
    "        print(j)\n",
    "        if j + batch_size > len(train_data):\n",
    "            break\n",
    "        # c = cs[j : j + 32]\n",
    "        # q = qs[j : j + 32]\n",
    "        q = train_data[j : j + batch_size]\n",
    "\n",
    "        outputs = process_long_texts(q, model, tokenizer, train=True)\n",
    "        target_outputs = process_long_texts(q, base_model, tokenizer, train=True)\n",
    "        #inputs = tokenizer(q, return_tensors=\"pt\", padding=True, max_length = 512, truncation=True)\n",
    "        # if torch.cuda.is_available():\n",
    "        #     for k, v in inputs.items():\n",
    "        #         inputs[k] = v.cuda()\n",
    "        # outputs = model(pooling=True, **inputs)\n",
    "        # target_outputs = base_model(pooling=True, **inputs)\n",
    "\n",
    "        loss, loss_partial = loss_fn(target_outputs, outputs, [64, 128, 256, 384, 768])\n",
    "        loss_reg = loss_fn_reg(target_outputs, outputs)\n",
    "        loss_topk = loss_fn_topk(target_outputs, outputs, [64, 128, 256, 384, 768])\n",
    "\n",
    "        loss = loss + loss_reg + loss_topk\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step() \n",
    "        ls.append(loss.item())\n",
    "        epoch_loss.append(loss.item())\n",
    "        running_loss.append(loss.item())\n",
    "        for k, v in loss_partial.items():\n",
    "            partial_running_loss[k].append(v.item())\n",
    "        if len(running_loss) % 10 == 0:\n",
    "            print(\"Batch:\", j, \"loss:\", np.mean(running_loss))\n",
    "            #wandb.log({\"batch\": j, \"loss\": np.mean(running_loss)} | {f\"loss_{k}\": np.mean(v) for k, v in partial_running_loss.items()})\n",
    "            partial_running_loss = {64: [], 128: [], 256: [], 384: [], 768:[]}\n",
    "            running_loss = []\n",
    " \n",
    "    model.eval()\n",
    "    base_model.eval()\n",
    "    eval_loss = []\n",
    "    partial_eval_loss = {64: [], 128: [], 256: [], 384: [], 768:[]}\n",
    "    \n",
    "\n",
    "    for j in range(0, len(test_data), batch_size):\n",
    "        if j + batch_size > len(test_data):\n",
    "            break\n",
    "        q = test_data[j : j + batch_size]\n",
    "    \n",
    "        # Process long texts into embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = process_long_texts(q, model, tokenizer, train=False)\n",
    "            target_outputs = process_long_texts(q, base_model, tokenizer, train=False)\n",
    "            \n",
    "            # Compute the losses\n",
    "            loss, loss_partial = loss_fn(target_outputs, outputs, [64, 128, 256, 384, 768])\n",
    "            eval_loss.append(loss.item())\n",
    "            \n",
    "            # Collect partial losses\n",
    "            for k, v in loss_partial.items():\n",
    "                partial_eval_loss[k].append(v.item())\n",
    "    \n",
    "    #wandb.log({\"epoch\": i, \"epoch_loss\": np.mean(epoch_loss), \"eval_loss\": np.mean(eval_loss)} | {f\"eval_loss_{k}\": np.mean(v) for k, v in partial_eval_loss.items()})\n",
    "    print(\"Epoch:\", i, \"loss:\", np.mean(epoch_loss), \"eval_loss:\", np.mean(eval_loss))\n",
    "    os.makedirs(f\"modelsbert1/{run_name }\", exist_ok=True)\n",
    "    torch.save(model.state_dict(), f\"modelsbert1/{run_name}/{i}_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!git config --global --add safe.directory /home/shreya34/matryoshka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
